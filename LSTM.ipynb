{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucifer/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/interpolated_co2.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Train: Up to 2024-12-31 | Test: 2025-01-01 to 2025-04-13\n",
    "train_data = df[df['Date'] <= '2024-12-31']\n",
    "test_data = df[(df['Date'] >= '2025-01-01') & (df['Date'] <= '2025-04-13')]\n",
    "\n",
    "# Normalize only the CO2 column\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data[['CO2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=60):\n",
    "    x, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "seq_length = 60\n",
    "x_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucifer/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0122\n",
      "Epoch 2/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.5904e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 5.4802e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.6175e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9989e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.4358e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 7.4121e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 4.7184e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.1754e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.8546e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x308c5cb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)),\n",
    "    LSTM(units=50),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# Combine train and test CO2 for sliding window\n",
    "full_data = pd.concat((train_data[['CO2']], test_data[['CO2']]), axis=0)\n",
    "full_scaled = scaler.transform(full_data)\n",
    "\n",
    "# Create test sequences\n",
    "x_test = []\n",
    "for i in range(len(train_scaled), len(full_scaled)):\n",
    "    x_test.append(full_scaled[i-seq_length:i])\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Predict\n",
    "predictions_scaled = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8750\n",
      "MAE: 0.6739\n",
      "Accuracy: 99.84%\n",
      "Saved to Predictions/lstm_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the last N rows from test_data matching prediction length\n",
    "actual_values = test_data['CO2'].values[-len(predictions):]\n",
    "pred_dates = test_data['Date'].values[-len(predictions):]\n",
    "\n",
    "# Calculate metrics\n",
    "rmse = sqrt(mean_squared_error(actual_values, predictions))\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "accuracy = 100 - (np.mean(np.abs((actual_values - predictions.reshape(-1)) / actual_values)) * 100)\n",
    "\n",
    "# Save predictions in requested format\n",
    "results = pd.DataFrame({\n",
    "    'Date': pred_dates,\n",
    "    'Actual': actual_values,\n",
    "    'Predicted': predictions.reshape(-1)\n",
    "})\n",
    "\n",
    "os.makedirs('Predictions', exist_ok=True)\n",
    "results.to_csv('Predictions/lstm_predictions.csv', index=False)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "print('Saved to Predictions/lstm_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
